{{- $root := . -}}
{{- if .Values.worker.enabled }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: {{ .Values.appName }}-sidekiq
  name: {{ .Values.appName }}-sidekiq
  namespace: {{ .Release.Namespace }}
spec:
  revisionHistoryLimit: 1
  selector:
    matchLabels:
      app: {{ .Values.appName }}-sidekiq
  strategy:
    type: {{ .Values.worker.strategyType }}
    rollingUpdate:
      maxSurge: {{ .Values.worker.maxSurge }}
      maxUnavailable: {{ .Values.worker.maxUnavailable }}
  template:
    metadata:
      labels:
        app: {{ .Values.appName }}-sidekiq
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: {{ .Values.affinityWeight }}
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: {{ .Values.matchExpressions.key }}
                      operator: {{ .Values.matchExpressions.operator }}
                      values:
                        - {{ .Values.appName }}-sidekiq
                topologyKey: {{ .Values.topologyKey }}
      securityContext:
        fsGroup: {{ $root.Values.fsGroup }}
      volumes:
        - name: imagemagick-policy-volume # ConfigMap volume with new policy
          configMap:
            name: {{ $root.Release.Namespace }}-imagemagick-policy
        - name: imagemagick-shared-volume # Shared writable volume for merged policy
          emptyDir: {}
        {{- if $root.Values.mockData.enabled }}
        - name: vets-api-mockdata
          emptyDir: {}
        {{- end }}
        - name: clamav-volume
          emptyDir: {}
        - name: ddsocket
          hostPath:
            path: /var/run/datadog
{{ toYaml .Values.common.volumes | indent 8 }}
      {{- if .Values.mockData.enabled }}
      initContainers:
        - name: merge-imagemagick-policy
           # need Imagemagick policy file from Vets API
          image: "{{ $root.Values.image.value }}:{{ $root.Values.image.tag }}"
          command:
            - /bin/sh
            - -c
            - |
              rails runner '
              require "nokogiri"
              # Read the original and new policy files
              policy1 = Nokogiri::XML(File.read("/etc/ImageMagick-6/policy.xml"))
              policy2 = Nokogiri::XML(File.read("/tmp_policy/new-policy.xml"))
              # Merge the policies by appending from the new file
              policy2.xpath("//policy").each do |policy|
                policy1.root.add_child(policy)
              end
              # Write the merged policy to shared volume
              File.write("/tmp_workspace/policy.xml", policy1.to_xml)
              '
          volumeMounts:
            - name: imagemagick-policy-volume
              mountPath: /tmp_policy/new-policy.xml
              subPath: new-policy.xml
            - name: imagemagick-shared-volume
              mountPath: /tmp_workspace
        - name: vets-api-mockdata
          image: "{{ $root.Values.git_container_repo }}:{{ $root.Values.git_container_version }}"
          args:
            - clone
            - --single-branch
            - --
            - https://$(GITHUB_TOKEN)@github.com/department-of-veterans-affairs/vets-api-mockdata.git
            - /data
          env:
            - name: GITHUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: github-token
                  key: github-token
          volumeMounts:
            - name: vets-api-mockdata
              mountPath: /data
          {{- if default $root.Values.common.initContainers }}
{{ toYaml $root.Values.common.initContainers | indent 8 }}
          {{- end }}
      {{- end }}
      containers:
        - image: "{{ .Values.image.value }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          name: {{ .Values.appName }}-sidekiq
          securityContext:
            runAsUser: 0
          ## TODO: Be sure that this is the correct way to start sidekiq
          command:
{{ toYaml .Values.worker.containers.command | indent 12 }}
          args:
{{ toYaml .Values.worker.containers.args | indent 12 }}
          # source and destination files
          livenessProbe: #ensure app is serving requests properly and know when to restart a container
            httpGet:
              path: {{ .Values.worker.healthCheck.requestPath }}
              port: {{ .Values.worker.healthCheck.port }}
            initialDelaySeconds: {{ .Values.worker.healthCheck.initialDelaySeconds }}
            timeoutSeconds: {{ .Values.worker.healthCheck.timeoutSeconds }}
            failureThreshold:  {{ .Values.worker.healthCheck.liveness.failureThreshold }}
          readinessProbe: #ensure container is ready to start accepting traffic
            httpGet:
              path: {{ .Values.worker.healthCheck.readinessPath }}
              port: {{ .Values.worker.healthCheck.readinessPort }}
            initialDelaySeconds: {{ .Values.worker.healthCheck.initialDelaySeconds }}
            timeoutSeconds: {{ .Values.worker.healthCheck.timeoutSeconds }}
            failureThreshold: {{ .Values.worker.healthCheck.readiness.failureThreshold }}
          lifecycle:
            preStop:
              exec:
                # SIGTERM triggers a quick exit; gracefully terminate instead
                command: {{ .Values.worker.healthCheck.command }}
          resources:
{{ toYaml .Values.worker.resources | indent 12 }}
          volumeMounts:
            - name: imagemagick-shared-volume
              mountPath: /etc/ImageMagick-6/policy.xml
              subPath: policy.xml
            - name: clamav-volume
              mountPath: /app/clamav_tmp
              {{- if $root.Values.mockData.enabled }}
            - name: vets-api-mockdata
              mountPath: /app/config/vets-api-mockdata
              {{- end }}
            - name: ddsocket
              mountPath: /var/run/datadog
{{ toYaml .Values.common.volumeMounts | indent 12 }}
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: GIT_REVISION
              value: {{ .Values.image.tag}}
{{ toYaml .Values.worker.envSecrets | indent 12 }}
          {{- range $keys, $key := .Values.common.secrets }}
          {{- range $secrets, $secret := $key }}
            - name: {{ $secret.env_var }}
              valueFrom:
                secretKeyRef:
                  name: {{ $keys }}
                  key: {{ $secret.name }}
          {{- end }}
          {{- end }}
          envFrom:
            - secretRef:
                name: common-environment-ssm-vars
        {{- if $root.Values.clamav.enabled  }}
        - name: clamav
          image: "{{ $root.Values.clamav.image.value }}:{{ $root.Values.clamav.image.tag }}"
          imagePullPolicy: {{ $root.Values.clamav.image.pullPolicy }}
          ports:
            - containerPort: 3310
              name: clamavport
              protocol: TCP
          readinessProbe:
            tcpSocket:
              port: clamavport
            failureThreshold: {{ $root.Values.clamav.readinessProbe.failureThreshold }}
            initialDelaySeconds: 30
            periodSeconds: {{ $root.Values.clamav.readinessProbe.periodSeconds }}
            timeoutSeconds: {{ $root.Values.clamav.readinessProbe.timeoutSeconds }}
            successThreshold: {{ $root.Values.clamav.readinessProbe.successThreshold }}
          startupProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - |
                  clamscan --version || echo "ClamAV failed to start"
                  echo -n "clamav.startup.success:1|c" | nc -u -w1 localhost 8125
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 10
            timeoutSeconds: 30
            successThreshold: 1
          lifecycle:
            postStart:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - freshclam --config-file /etc/clamav/freshclam.conf
          resources:
            requests:
              cpu: "{{ $root.Values.clamav.requestedCPU }}"
              memory: "{{ $root.Values.clamav.requestedMemory }}"
          volumeMounts:
            - name: clamav-volume
              mountPath: /vets-api
        {{- end }}
        {{- if $root.Values.worker.socatProxyEnabled }}
        - name: socat-proxy
          image: {{ $root.Values.socatImage }}
          args:
            - -s
            - -u
            - udp-recv:8125
            - unix-sendto:/var/run/datadog/dsd.socket
          volumeMounts:
            - name: ddsocket
              mountPath: /var/run/datadog
          resources:
            requests:
              cpu: 100m
              memory: 32Mi
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - netstat -anu | grep 8125
            initialDelaySeconds: 30
            failureThreshold: {{ $root.Values.socat.readinessProbe.failureThreshold }}
            periodSeconds: {{ $root.Values.socat.readinessProbe.periodSeconds }}
            timeoutSeconds: {{ $root.Values.socat.readinessProbe.timeoutSeconds }}
            successThreshold: {{ $root.Values.socat.readinessProbe.successThreshold }}
          startupProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - |
                  # 2. Test connectivity to the Unix socket
                  echo "socat connectivity test" | socat -u - UNIX-CONNECT:/var/run/datadog/dsd.socket || echo "socat failed to connect to Unix socket"
                  # 3. End-to-end data transmission test
                  echo "socat end-to-end test" | socat -u - udp-sendto:localhost:8125 || echo "socat failed end-to-end test"
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 10
            timeoutSeconds: 30
            successThreshold: 1
        {{- end }}
      terminationGracePeriodSeconds: {{ .Values.worker.terminationGracePeriodSeconds }} # put your longest Job time here plus security time.
      serviceAccountName: {{ .Values.serviceAccount.name }}
{{- end }}
